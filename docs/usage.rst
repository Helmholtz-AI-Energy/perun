.. _usage:

Usage
=====

.. _cmd-line:

Command line
------------

perun includes a command line tool which, besides the ``monitor`` subcommand, includes extra utilities that facilitates configuring perun and the data it collects. To get help regarding the perun command and any of its subcommands, the option ``--help`` is available for all of them.

monitor
~~~~~~~

To start monitoring your python applications, simply use

.. code-block:: console

    $ perun monitor your_app.py

This also applies MPI applications

.. code-block:: console

    $ mpirun -N 4 perun monitor your_app.py

perun will not disrupt your applications usage of MPI, and will quietly collect hardware data from all the different nodes being used. At the end, you will get a single report based on the data from all the nodes and their hardware components.

To modify the peruns behaviour, the command accepts options right after the perun command, like this:

.. code-block:: console

    $ perun --format json --raw --sampling_rate 5 monitor your_app.py

Or if environmental variables are prefered:

.. code-block:: console

    $ PERUN_FORMAT=json perun monitor your_app.py

A combination of both also works. If you have a set of options that works for your workflow, you can save them on '.perun.ini' file, and perun will use them automatically. For more info on the configuration options and file, check the :ref:`configuration` section.

sensors
~~~~~~~

To get a quikc overview of which interfaces and information perun has access to, you can use the ``sensors`` subcommand.

.. code-block:: console

    $ perun sensors
    Rank: 0
    NVIDIA ML:
        GPU-ffaa4aca-7ecb-f1ad-b36d-a71e094b183b

    PSUTIL:
        NET_WRITE_BYTES
        CPU_USAGE
        RAM_USAGE
        DISK_READ_BYTES
        NET_READ_BYTES
        DISK_WRITE_BYTES

    Hostnames:
        uc2n520.localdomain: [0]

perun will print an overview of the interfaces and individual "sensors" available on each mpi rank, and to which host node the mpi ranks belong to.

export
~~~~~~

perun supports multiple ouput formats, and can transform its data from one format to another (with some exceptions).

.. code-block:: console

    $ perun export perun_results/forward_22149666.hdf5 exported_results/ csv

The command takes as a first argument one of the output files of perun, as a second argument where the location where the new file will be saved, and the format it will be exported to. The input file needs to be a ``json``, ``hdf5`` or ``pickle`` formated file, as perun can easily reconstruct the original data structures from those files. The output format can be ``text``, ``json``, ``hdf5``, ``pickle``, ``csv`` and ``bench``

showconf
~~~~~~~~

To get a quick overview of the current configuration that perun is using, use the ``showconf`` subcommand.

.. code-block:: console

    $ perun showconf
    [post-processing]
    pue = 1.58
    emissions_factor = 0.262
    price_factor = 34.6

    [monitor]
    sampling_rate = 1

    [output]
    app_name
    run_id
    format = text
    data_out = ./perun_results
    depth
    raw = False

    [benchmarking]
    bench_enable = False
    bench_rounds = 10
    bench_warmup_rounds = 1

    [debug]
    log_lvl = ERROR


The command will print the current perun configuration in ``.ini`` format, which can be used as a starting point for your own ``.perun.ini`` file.

.. code-block:: console

    $ perun showconf > .perun.ini


To get the default configuration, simply add the ``--default`` flag.

.. code-block:: console

    $ perun showconf --default




Decorator
---------

To monitor a particular part of your code, you can use the ``@monitor`` decorator on the desired function.


.. code-block:: python

    import time
    from perun.decorator import monitor

    @monitor()
    def your_sleep_function(n: int):
        time.sleep(n)


The decorator accepts the same options as the configuration file or the command line.

.. code-block:: python

    import time
    from perun.decorator import monitor

    @monitor(format="csv", pue=1.05)
    def your_sleep_function(n: int):
        time.sleep(n)

.. attention::

    perun will generate an output file each time an the function is called.



.. _benchmarking:

Benchmarking
------------

*Benchmarking mode* can be enabled by using the special flag ``--bench`` or using the argument ``bench=True`` on the decorator. Instead of running the code a single time, perun will instead run a your code a configurable number of times and will collect statistics about it.

.. code-block:: console

    $ perun --bench monitor your_script.py

This will change the what information gets retured by perun, with most of the output formats having to adjust for the extra information. This is the text output generated by perun when using benchmarking mode:

.. code-block:: console

    App name: main
    Run ID: 2023-03-22T17:10:31.825947
    +-----------------+---------+---------+----------+---------+
    | Name            |    mean |     std |      max |     min |
    +-----------------+---------+---------+----------+---------+
    | RUNTIME [s]     |  10.009 |   0.001 |   10.010 |  10.008 |
    | POWER [W]       |   6.945 |   0.177 |    7.288 |   6.708 |
    | CPU_UTIL [%]    |  13.509 |   3.944 |   20.291 |   9.645 |
    | MEM_UTIL [%]    |   0.500 |   0.001 |    0.501 |   0.498 |
    | DISK_READ [kB]  |   1.200 |   1.833 |    4.000 |   0.000 |
    | DISK_WRITE [kB] | 767.200 | 590.400 | 1964.000 |  60.000 |
    | ENERGY [J]      |  69.576 |   1.849 |   73.203 |  67.112 |
    +-----------------+---------+---------+----------+---------+
